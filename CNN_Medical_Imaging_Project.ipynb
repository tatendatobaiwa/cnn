{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtylxm8fo9uOYUvOxr6PSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatendatobaiwa/cnn/blob/main/CNN_Medical_Imaging_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***SIMPLE CNN MODEL BUILD FOR LUNG CANCER IMAGING***\n"
      ],
      "metadata": {
        "id": "uTrMiFdV0cSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Mount Drive**"
      ],
      "metadata": {
        "id": "APUqAdq90e3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdecZ6Hd0iTL",
        "outputId": "2dee267d-2ceb-43ed-97db-cccc2940ee19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Create Directories in Drive**"
      ],
      "metadata": {
        "id": "j1Feq2kl0v2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Install Dependenices**"
      ],
      "metadata": {
        "id": "WKEjmsby03rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow==2.13.0\n",
        "!pip install -q tensorflow-addons==0.23.0\n",
        "!pip install albumentations==1.3.0\n",
        "!pip install numpy==1.24.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUdJXYJa04lM",
        "outputId": "3e49ce6b-d993-4b0a-b07b-8e22e70a1e74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations==1.3.0 in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (1.24.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (0.25.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (6.0.2)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (4.11.0.86)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (1.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.5.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (3.5.0)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "project_path = '/content/drive/MyDrive/CNN_Medical_Imaging_Project'\n",
        "sys.path.append(project_path)"
      ],
      "metadata": {
        "id": "PqoGmx2I06o8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mini Step 3a: Verify Fixes**"
      ],
      "metadata": {
        "id": "0yMbO_Y23psL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"TensorFlow Addons version: {tfa.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kB0Nwn823qKa",
        "outputId": "2db20dd4-e4d9-46c9-9583-230d8ffd8d6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.13.0\n",
            "TensorFlow Addons version: 0.23.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: data_processing.py: Load and Preprocess Data**"
      ],
      "metadata": {
        "id": "_eEmtj293vuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import albumentations as A\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class AlbumentationsSequence(Sequence):\n",
        "    \"\"\"Custom sequence for batching and augmenting images.\"\"\"\n",
        "    def __init__(self, images, labels, batch_size, transform):\n",
        "        self.images = images  # Array of images (uint8)\n",
        "        self.labels = labels  # Array of integer labels\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.batch_size\n",
        "        end = min((idx + 1) * self.batch_size, len(self.images))\n",
        "        batch_images = self.images[start:end]\n",
        "        batch_labels = self.labels[start:end]\n",
        "        # Apply augmentations and convert to 3-channel RGB\n",
        "        augmented = [self.transform(image=img)['image'] for img in batch_images]\n",
        "        augmented = np.array(augmented)\n",
        "        augmented = np.stack((augmented,) * 3, axis=-1)  # Grayscale to RGB\n",
        "        return augmented, batch_labels\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Handles loading and preprocessing of image data.\"\"\"\n",
        "    def __init__(self, target_size=(224, 224)):  # Fixed typo in target_size\n",
        "        self.target_size = target_size\n",
        "        self.class_names = ['benign', 'malignant', 'normal']\n",
        "\n",
        "    def load_images(self, data_dir):\n",
        "        \"\"\"Load images and labels from a directory with class subfolders.\"\"\"\n",
        "        data_dir = Path(data_dir)\n",
        "        images = []\n",
        "        labels = []\n",
        "        print(f\"Loading images from {data_dir}\")\n",
        "        for label, class_name in enumerate(self.class_names):\n",
        "            class_dir = data_dir / class_name\n",
        "            if not class_dir.exists():\n",
        "                print(f\"Warning: Directory {class_dir} does not exist.\")\n",
        "                continue\n",
        "            img_paths = list(class_dir.glob('*.[jp][pn][gf]'))  # Match .jpg, .jpeg, .png\n",
        "            print(f\"Found {len(img_paths)} images in {class_name}\")\n",
        "            for img_path in img_paths:\n",
        "                img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
        "                if img is None:\n",
        "                    print(f\"Warning: Failed to load {img_path}\")\n",
        "                    continue\n",
        "                img = cv2.resize(img, self.target_size)\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "        if not images:\n",
        "            print(\"No images loaded.\")\n",
        "        else:\n",
        "            print(f\"Total images loaded: {len(images)}\")\n",
        "        return np.array(images), np.array(labels, dtype=np.int32), self.class_names\n",
        "\n",
        "    def create_generators(self, X_train, y_train, X_val, y_val, batch_size=32):\n",
        "        \"\"\"Create training and validation generators with augmentation.\"\"\"\n",
        "        train_transform = A.Compose([\n",
        "            A.Rotate(limit=20, p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=0, p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.ElasticTransform(alpha=34, sigma=4, p=0.3),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "            A.Normalize(mean=0.0, std=1.0),\n",
        "        ])\n",
        "        val_transform = A.Compose([\n",
        "            A.Normalize(mean=0.0, std=1.0),\n",
        "        ])\n",
        "        train_gen = AlbumentationsSequence(X_train, y_train, batch_size, train_transform)\n",
        "        val_gen = AlbumentationsSequence(X_val, y_val, batch_size, val_transform)\n",
        "        return train_gen, val_gen\n",
        "\n",
        "    def load_test_images(self, test_dir):\n",
        "        \"\"\"Load and preprocess test images.\"\"\"\n",
        "        return self.load_images(test_dir)  # Reuses load_images for consistency\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test usage\n",
        "    processor = DataProcessor()\n",
        "    X_train, y_train, class_names = processor.load_images('/content/drive/MyDrive/CNN_Medical_Imaging_Project/data/raw/train')\n",
        "    print(f\"Loaded {len(X_train)} training images\")"
      ],
      "metadata": {
        "id": "OWzCeWnA32HU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4f08a8-3ea8-4f88-b718-176217fd3345"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from /content/drive/MyDrive/CNN_Medical_Imaging_Project/data/raw/train\n",
            "Found 120 images in benign\n",
            "Found 335 images in malignant\n",
            "Found 416 images in normal\n",
            "Total images loaded: 871\n",
            "Loaded 871 training images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: train.py: Model Training**"
      ],
      "metadata": {
        "id": "CtziedEK32e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from data_processing import DataProcessor\n",
        "from model_mobilenet import create_mobilenet_model\n",
        "\n",
        "def train_model(train_gen, val_gen, class_names, epochs=50):\n",
        "    # Ensure train_gen.labels is a NumPy array of integers\n",
        "    if not isinstance(train_gen.labels, np.ndarray):\n",
        "        train_gen.labels = np.array(train_gen.labels)\n",
        "    train_gen.labels = train_gen.labels.astype(int)\n",
        "\n",
        "    # Debugging prints\n",
        "    print(\"Type of train_gen.labels:\", type(train_gen.labels))\n",
        "    print(\"Shape of train_gen.labels:\", train_gen.labels.shape)\n",
        "    print(\"First few values of train_gen.labels:\", train_gen.labels[:5] if len(train_gen.labels) > 0 else \"Empty\")\n",
        "\n",
        "    # Validate train_gen.labels\n",
        "    if len(train_gen.labels) == 0:\n",
        "        raise ValueError(\"train_gen.labels is empty. No training labels available.\")\n",
        "\n",
        "    # Compute unique classes\n",
        "    classes = np.unique(train_gen.labels)\n",
        "    print(\"Classes:\", classes)\n",
        "    if len(classes) == 0:\n",
        "        raise ValueError(\"No unique classes found in train_gen.labels.\")\n",
        "\n",
        "    print(\"Type of classes[0]:\", type(classes[0]))\n",
        "\n",
        "    # Compute class weights\n",
        "    class_weights = compute_class_weight('balanced', classes=classes, y=train_gen.labels)\n",
        "    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = create_mobilenet_model(num_classes=len(class_names))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "    checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "    # Initial training\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=epochs,\n",
        "        callbacks=[early_stop, checkpoint, reduce_lr],\n",
        "        class_weight=class_weights_dict\n",
        "    )\n",
        "\n",
        "    # Fine-tuning\n",
        "    set_trainable = False\n",
        "    for layer in model.layers:\n",
        "        if layer.name == 'block_13_expand':\n",
        "            set_trainable = True\n",
        "        if set_trainable:\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Recompile for fine-tuning\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Fine-tuning training\n",
        "    history_fine = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=epochs,\n",
        "        callbacks=[early_stop, checkpoint, reduce_lr],\n",
        "        class_weight=class_weights_dict\n",
        "    )\n",
        "\n",
        "    return model, history, history_fine\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    processor = DataProcessor()\n",
        "\n",
        "    # Load all data from the training directory\n",
        "    X_train_full, y_train_full, class_names = processor.load_images('/content/drive/MyDrive/CNN_Medical_Imaging_Project/data/raw/train')\n",
        "\n",
        "    # Debugging loaded data\n",
        "    print(\"X_train_full shape:\", X_train_full.shape)\n",
        "    print(\"y_train_full shape:\", y_train_full.shape)\n",
        "    print(\"First few y_train_full labels:\", y_train_full[:5])\n",
        "    print(\"Class names:\", class_names)\n",
        "\n",
        "    # Check if data was loaded\n",
        "    if len(X_train_full) == 0 or len(y_train_full) == 0:\n",
        "        raise ValueError(\"No training data loaded. Verify the training directory.\")\n",
        "\n",
        "    # Split the training data into 80% training and 20% validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42)\n",
        "\n",
        "    # Debugging split data\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"X_val shape:\", X_val.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"y_val shape:\", y_val.shape)\n",
        "\n",
        "    # Create generators\n",
        "    train_gen, val_gen = processor.create_generators(X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # Train the model\n",
        "    model, history, history_fine = train_model(train_gen, val_gen, class_names)\n",
        "\n",
        "    # Load test data for final evaluation\n",
        "    X_test, y_test, _ = processor.load_images('/content/drive/MyDrive/CNN_Medical_Imaging_Project/data/raw/test')\n",
        "    print(\"X_test shape:\", X_test.shape)\n",
        "    print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test loss: {test_loss:.4f}\")\n",
        "    print(f\"Test accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXAqrXoA3_K8",
        "outputId": "d8d62272-40f0-4fa0-8f2c-d6253ba1d782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from /content/drive/MyDrive/CNN_Medical_Imaging_Project/data/raw/train\n",
            "Found 120 images in benign\n",
            "Found 335 images in malignant\n",
            "Found 416 images in normal\n",
            "Total images loaded: 871\n",
            "X_train_full shape: (871, 224, 224)\n",
            "y_train_full shape: (871,)\n",
            "First few y_train_full labels: [0 0 0 0 0]\n",
            "Class names: ['benign', 'malignant', 'normal']\n",
            "X_train shape: (696, 224, 224)\n",
            "X_val shape: (175, 224, 224)\n",
            "y_train shape: (696,)\n",
            "y_val shape: (175,)\n",
            "Type of train_gen.labels: <class 'numpy.ndarray'>\n",
            "Shape of train_gen.labels: (696,)\n",
            "First few values of train_gen.labels: [0 1 1 1 2]\n",
            "Classes: [0 1 2]\n",
            "Type of classes[0]: <class 'numpy.int64'>\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 32s 1s/step - loss: 1.2499 - accuracy: 0.4885 - val_loss: 0.7865 - val_accuracy: 0.5086 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50\n",
            "22/22 [==============================] - 29s 1s/step - loss: 0.9135 - accuracy: 0.5718 - val_loss: 0.4980 - val_accuracy: 0.8114 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 34s 2s/step - loss: 0.7531 - accuracy: 0.6566 - val_loss: 0.5918 - val_accuracy: 0.6686 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 36s 2s/step - loss: 0.6906 - accuracy: 0.6739 - val_loss: 0.4143 - val_accuracy: 0.8286 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "12/22 [===============>..............] - ETA: 10s - loss: 0.7186 - accuracy: 0.6463"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: evaluate.py: Model Evaluation**"
      ],
      "metadata": {
        "id": "kIfjvQec4FK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, class_names, save_path=None):\n",
        "    \"\"\"\n",
        "    Evaluate a trained model on test data with classification metrics and visualizations.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model.\n",
        "    - X_test: Test images (numpy array).\n",
        "    - y_test: True labels (numpy array).\n",
        "    - class_names: List of class names (e.g., ['benign', 'malignant', 'normal']).\n",
        "    - save_path: Optional path to save confusion matrix plot (e.g., 'confusion_matrix.png').\n",
        "    \"\"\"\n",
        "    # Predict probabilities and classes\n",
        "    y_pred_probs = model.predict(X_test, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"Classification Report:\")\n",
        "    report = classification_report(y_test, y_pred_classes, target_names=class_names)\n",
        "    print(report)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        print(f\"Confusion matrix saved to {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Per-Class Sensitivity and Specificity\n",
        "    print(\"\\nPer-Class Metrics:\")\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        tp = cm[i, i]\n",
        "        fn = np.sum(cm[i, :]) - tp\n",
        "        fp = np.sum(cm[:, i]) - tp\n",
        "        tn = np.sum(cm) - tp - fn - fp\n",
        "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        print(f\"{class_name}: Sensitivity = {sensitivity:.2f}, Specificity = {specificity:.2f}\")\n",
        "\n",
        "    # ROC-AUC Score\n",
        "    y_test_bin = label_binarize(y_test, classes=range(len(class_names)))\n",
        "    auc = roc_auc_score(y_test_bin, y_pred_probs, multi_class='ovr')\n",
        "    print(f\"\\nROC-AUC Score (One-vs-Rest): {auc:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from tensorflow.keras.models import load_model\n",
        "    from data_processing import DataProcessor\n",
        "\n",
        "    # Load test data instead of validation data\n",
        "    processor = DataProcessor()\n",
        "    X_test, y_test, class_names = processor.load_test_images('/content/drive/MyDrive/CNN_Medical_Imaging_Project/data/raw/test')\n",
        "\n",
        "    # Load the trained model\n",
        "    model = load_model('best_model.h5')\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(model, X_test, y_test, class_names, save_path='confusion_matrix.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "pR37Q85d4HjO",
        "outputId": "44e2e767-be4a-46d1-bac3-cbf3869084c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7082aa119d62>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'confusion_matrix.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-7082aa119d62>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X_test, y_test, class_names, save_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Predict probabilities and classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0my_pred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0my_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2577\u001b[0m                         )\n\u001b[1;32m   2578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2580\u001b[0m                     \u001b[0;34m\"Unexpected result of `predict_function` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m                     \u001b[0;34m\"(Empty batch_outputs). Please use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: xai.py: Implementation of Explainable AI (Grad-CAM)**"
      ],
      "metadata": {
        "id": "UCs2RgYL4M7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def get_gradcam_heatmap(model, img_array, layer_name):\n",
        "    \"\"\"\n",
        "    Generate a Grad-CAM heatmap for a given image.\n",
        "\n",
        "    Args:\n",
        "        model: Trained Keras model.\n",
        "        img_array: Input image array with shape (1, H, W, C).\n",
        "        layer_name: Name of the convolutional layer to use for Grad-CAM.\n",
        "\n",
        "    Returns:\n",
        "        Heatmap as a numpy array.\n",
        "    \"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        loss = predictions[:, np.argmax(predictions[0])]  # Target the predicted class\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def superimpose_heatmap(img, heatmap, alpha=0.4):\n",
        "    \"\"\"\n",
        "    Superimpose a Grad-CAM heatmap on the original image.\n",
        "\n",
        "    Args:\n",
        "        img: Original image (numpy array, shape (H, W, C), values in [0, 1]).\n",
        "        heatmap: Grad-CAM heatmap (numpy array).\n",
        "        alpha: Transparency factor for the heatmap overlay.\n",
        "\n",
        "    Returns:\n",
        "        Superimposed image as a numpy array (uint8).\n",
        "    \"\"\"\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = heatmap * alpha + img * 255  # Scale img back to 0-255\n",
        "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
        "    return superimposed_img\n",
        "\n",
        "def visualize_explanations(model, X_test, y_test, class_names, layer_name, num_images=5, save_dir=None):\n",
        "    \"\"\"\n",
        "    Visualize Grad-CAM explanations for test images.\n",
        "\n",
        "    Args:\n",
        "        model: Trained Keras model.\n",
        "        X_test: Test images (numpy array, shape (N, H, W, C)).\n",
        "        y_test: True labels (numpy array, shape (N,)).\n",
        "        class_names: List of class names (e.g., ['benign', 'malignant', 'normal']).\n",
        "        layer_name: Name of the layer to use for Grad-CAM.\n",
        "        num_images: Number of images to visualize.\n",
        "        save_dir: Optional directory to save the visualizations.\n",
        "    \"\"\"\n",
        "    if save_dir and not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    for i in range(min(num_images, len(X_test))):\n",
        "        img = X_test[i:i+1]  # Batch of 1\n",
        "        true_label = class_names[y_test[i]]\n",
        "        heatmap = get_gradcam_heatmap(model, img, layer_name)\n",
        "        superimposed_img = superimpose_heatmap(img[0], heatmap)\n",
        "\n",
        "        # Predict class for the image\n",
        "        pred_probs = model.predict(img, verbose=0)\n",
        "        pred_class = class_names[np.argmax(pred_probs)]\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img[0][:, :, 0], cmap='gray')  # Show first channel (grayscale)\n",
        "        plt.title(f'True: {true_label}\\nPred: {pred_class}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(superimposed_img)\n",
        "        plt.title('Grad-CAM')\n",
        "        plt.axis('off')\n",
        "\n",
        "        if save_dir:\n",
        "            plt.savefig(os.path.join(save_dir, f'gradcam_{i}_true_{true_label}_pred_{pred_class}.png'))\n",
        "            print(f\"Saved Grad-CAM for image {i} to {save_dir}\")\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from tensorflow.keras.models import load_model\n",
        "    from data_processing import DataProcessor\n",
        "\n",
        "    # Load test data\n",
        "    processor = DataProcessor()\n",
        "    X_test, y_test, class_names = processor.load_test_images('/content/drive/MyDrive/CNN_Medical_Imaging_Project/data/raw/test')\n",
        "\n",
        "    # Load the trained model\n",
        "    model = load_model('best_model.h5')  # Match the path from train.py\n",
        "\n",
        "    # Visualize explanations\n",
        "    layer_name = 'block_16_project'  # Adjusted for MobileNetV2, late conv layer\n",
        "    visualize_explanations(model, X_test, y_test, class_names, layer_name, num_images=5, save_dir='gradcam_outputs')"
      ],
      "metadata": {
        "id": "dX1c5wcn4TBn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}