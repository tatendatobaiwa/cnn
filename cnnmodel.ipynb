{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1cjsXgtWLzhDw6r-_PjUFhTrTqHDoPKjx",
      "authorship_tag": "ABX9TyNHZBQXxd/7jZHg3n++eRIr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatendatobaiwa/cnn/blob/main/cnnmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Mount Drive"
      ],
      "metadata": {
        "id": "r1CEpT9rVis0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbbXQjffE_34",
        "outputId": "73ac07d7-8ff4-48b8-8250-46aed57fe994"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Create Directories in Drive"
      ],
      "metadata": {
        "id": "8G_s0h7xVnPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Install Dependenices"
      ],
      "metadata": {
        "id": "mKdEpjSYXjrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras numpy pandas matplotlib scikit-learn opencv-python seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcERcuaqXnXy",
        "outputId": "4e7b2a1b-f92a-4bc5-b3a3-ae7098a97984"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Use a script to Load and Preprocess Data"
      ],
      "metadata": {
        "id": "ef8lTcDEZika"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def load_images_from_directory(directory: Path, target_size: tuple = (256, 256)) -> tuple:\n",
        "    \"\"\"\n",
        "    Load images from class subdirectories with enhanced error handling\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = ['benign', 'malignant', 'normal']\n",
        "\n",
        "    for label, class_name in enumerate(class_names):\n",
        "        class_dir = directory / class_name\n",
        "        if not class_dir.exists():\n",
        "            raise FileNotFoundError(f\"Class directory {class_dir} not found\")\n",
        "\n",
        "        for img_path in class_dir.glob('*'):\n",
        "            if img_path.suffix.lower() in ('.png', '.jpg', '.jpeg'):\n",
        "                try:\n",
        "                    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is None:\n",
        "                        continue\n",
        "                    img = cv2.resize(img, target_size)\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {img_path}: {str(e)}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "def preprocess_data(data_dir: str, test_dir: str, target_size: tuple = (256, 256),\n",
        "                   validation_split: float = 0.2, batch_size: int = 32) -> tuple:\n",
        "    \"\"\"\n",
        "    Complete data pipeline with proper train-val-test split\n",
        "    \"\"\"\n",
        "    # Convert to Path objects\n",
        "    data_path = Path(data_dir)\n",
        "    test_path = Path(test_dir)\n",
        "\n",
        "    # Load and split data\n",
        "    X, y = load_images_from_directory(data_path / 'train')\n",
        "    X = X[..., np.newaxis] / 255.0  # Normalize and add channel dimension\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=validation_split, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    # Data augmentation configuration\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator()\n",
        "\n",
        "    # Create generators\n",
        "    train_generator = train_datagen.flow(\n",
        "        X_train, y_train, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = val_datagen.flow(\n",
        "        X_val, y_val, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    # Load test data\n",
        "    test_images = []\n",
        "    test_files = []\n",
        "    for img_path in test_path.glob('*'):\n",
        "        if img_path.suffix.lower() in ('.png', '.jpg', '.jpeg'):\n",
        "            img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, target_size)\n",
        "            test_images.append(img)\n",
        "            test_files.append(img_path.name)\n",
        "\n",
        "    test_images = np.array(test_images)[..., np.newaxis] / 255.0\n",
        "\n",
        "    return train_generator, val_generator, test_images, test_files, X_val, y_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVOBFpfWZt5X",
        "outputId": "55c5197c-dec7-45e7-eed4-cbf44931e0db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 28\n",
            "Validation images: 7\n",
            "Test images: 197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Model Development"
      ],
      "metadata": {
        "id": "z2R4wHkrdeQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "def create_cnn_model(input_shape: tuple = (256, 256, 1)) -> Sequential:\n",
        "    \"\"\"\n",
        "    Optimized CNN architecture with proper regularization\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.6),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def train_model(model: Sequential, train_gen, val_gen, epochs: int = 50,\n",
        "               model_path: str = 'models/best_model.h5') -> dict:\n",
        "    \"\"\"\n",
        "    Training process with checkpointing and early stopping\n",
        "    \"\"\"\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=8, restore_best_weights=True),\n",
        "        ModelCheckpoint(model_path, save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history.history"
      ],
      "metadata": {
        "id": "HwzZ6JzrdhTg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Model Evaluation and Optimization"
      ],
      "metadata": {
        "id": "LwEZg4reeI6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_model(model, X_val, y_val, class_names: list = ['benign', 'malignant', 'normal']):\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation with visualization\n",
        "    \"\"\"\n",
        "    # Generate predictions\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val, y_pred_classes, target_names=class_names))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_val, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate accuracy per class\n",
        "    class_acc = {}\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        mask = y_val == i\n",
        "        class_acc[class_name] = np.mean(y_pred_classes[mask] == y_val[mask])\n",
        "\n",
        "    print(\"\\nClass-wise Accuracy:\")\n",
        "    for class_name, acc in class_acc.items():\n",
        "        print(f\"{class_name}: {acc:.2%}\")"
      ],
      "metadata": {
        "id": "ZyqwoFSXeMW1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Explainable AI (XAI) Integration"
      ],
      "metadata": {
        "id": "tmlxP1wHennm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def grad_cam(model, img_array, layer_name: str = 'conv2d_2', class_index: int = None):\n",
        "    \"\"\"\n",
        "    Enhanced Grad-CAM implementation with proper tensor handling\n",
        "    \"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if class_index is None:\n",
        "            class_index = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_index]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap).numpy()\n",
        "\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "\n",
        "    # Resize and convert to RGB\n",
        "    heatmap = cv2.resize(heatmap, (img_array.shape[2], img_array.shape[1]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    # Superimpose with original image\n",
        "    img = np.uint8(255 * img_array[0].squeeze())\n",
        "    superimposed_img = cv2.addWeighted(cv2.cvtColor(img, cv2.COLOR_GRAY2BGR), 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "    return superimposed_img\n",
        "\n",
        "def visualize_explanations(model, X_val, y_val, num_samples: int = 3):\n",
        "    \"\"\"\n",
        "    Visualize predictions with Grad-CAM explanations\n",
        "    \"\"\"\n",
        "    class_names = ['benign', 'malignant', 'normal']\n",
        "    indices = np.random.choice(len(X_val), num_samples, replace=False)\n",
        "\n",
        "    plt.figure(figsize=(15, 5 * num_samples))\n",
        "    for i, idx in enumerate(indices, 1):\n",
        "        img = X_val[idx]\n",
        "        true_label = class_names[y_val[idx]]\n",
        "\n",
        "        # Get prediction\n",
        "        pred = model.predict(np.expand_dims(img, axis=0))\n",
        "        pred_class = class_names[np.argmax(pred)]\n",
        "\n",
        "        # Generate explanation\n",
        "        explanation = grad_cam(model, np.expand_dims(img, axis=0))\n",
        "\n",
        "        # Plot results\n",
        "        plt.subplot(num_samples, 2, 2*i-1)\n",
        "        plt.imshow(img.squeeze(), cmap='gray')\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_class}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples, 2, 2*i)\n",
        "        plt.imshow(explanation)\n",
        "        plt.title(\"Grad-CAM Explanation\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qcfCtHW5eqSP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Train Model"
      ],
      "metadata": {
        "id": "oLXDqSOKsRIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from src.data import preprocess_data\n",
        "from src.model import create_cnn_model, train_model\n",
        "from src.evaluate import evaluate_model\n",
        "from src.xai import visualize_explanations\n",
        "\n",
        "# Configuration\n",
        "DATA_DIR = Path('data/raw')\n",
        "TEST_DIR = DATA_DIR / 'test'\n",
        "MODEL_PATH = 'models/best_model.h5'\n",
        "TARGET_SIZE = (256, 256)\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def main():\n",
        "    # Data preparation\n",
        "    train_gen, val_gen, test_images, test_files, X_val, y_val = preprocess_data(\n",
        "        DATA_DIR, TEST_DIR, target_size=TARGET_SIZE, batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    # Model training\n",
        "    model = create_cnn_model(input_shape=(*TARGET_SIZE, 1))\n",
        "    history = train_model(model, train_gen, val_gen, epochs=EPOCHS, model_path=MODEL_PATH)\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"\\nModel Evaluation:\")\n",
        "    evaluate_model(model, X_val, y_val)\n",
        "\n",
        "    # Explainability\n",
        "    print(\"\\nGenerating Explanations...\")\n",
        "    visualize_explanations(model, X_val, y_val, num_samples=3)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "NS1ddNOssFVm",
        "outputId": "654c5006-d989-46d2-d28e-ae6264e75fce"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-0ee94010b124>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_cnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize_explanations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}